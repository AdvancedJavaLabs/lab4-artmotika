[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/-hH64FG6)
## Лабораторная работа: Реализация MapReduce для анализа данных о продажах с ипользованием HADOOP!!!
# Цель работы

Ознакомиться с концепцией распределенных вычислений на примере модели MapReduce. Научиться разрабатывать многопоточную систему для обработки больших данных и применять её для анализа данных о продажах.
# Описание задачи

У вас в репозитории есть несколько CSV-файлов, представляющих данные о продажах, например:

    transaction_id,product_id,category,price,quantity
    1,101,electronics,300.00,2
    2,102,books,15.00,5
    3,101,electronics,300.00,1
    4,103,toys,25.00,4
    5,102,books,15.00,3

Необходимо:

  * Вычислить общую выручку для каждой категории товаров.
  * Подсчитать общее количество проданных товаров по категориям.
  * Отсортировать категории по общей выручке в порядке убывания.

Пример вывода:

    Category      Revenue    Quantity
    electronics   900.00     3
    books         120.00     8
    toys          100.00     4

# Требования
Основная часть:

  * Используем hadoop
  * Написать реализацию MapReduce для обработки CSV-файлов.
  * Реализовать многопоточность в каждой фазе:
      * Map — обработка строк из файлов.
      * Shuffle/Sort — группировка данных по категориям.
      * Reduce — вычисление итоговых значений для каждой категории.
  * Сохранить результат в файл.
  * Обеспечить потокобезопасность при работе с общими данными.
  * Реализовать поддержку одновременной обработки большого количества файлов.

Дополнительные задачи (по желанию):

* Добавить возможность выбора метрики анализа (например, подсчёт средней цены товара в категории).

# Результаты
Результатом работы является сам код, файл с результатами и экспериментальные данные по быстродействию работы написанного кода при изменении числа worker-ов / частей, на которые разбивается файл

Результаты:
```
кол-во воркеров     размер данных       время
1                   512кб               12719 ms.
1                   1024кб              9231 ms.
1                   2048кб              8211 ms.
1                   4096кб              7207 ms.
1                   8192кб              8206 ms.
1                   30000кб             7202 ms.
1                   512кб               11227 ms.
2                   512кб               11233 ms.
4                   512кб               12265 ms.
8                   512кб               12236 ms.
16                  512кб               14220 ms.
32                  512кб               15232 ms.
1                   1024кб              9205 ms.
2                   1024кб              10207 ms.
4                   1024кб              10241 ms.
8                   1024кб              10215 ms.
16                  1024кб              13214 ms.
32                  1024кб              15208 ms.
```

Вывод: увелечение кол-ва вооркеров только увеличивает время выполнения программы,
так как затраты на управления воркерами и передачу данных превышают выгоду от параллелизма. 
Возможно надо увеличить размер данных, чтобы задачи стали более вычислительно трудными. 

Также если увеличивать размер данных, то уменьшается время выполнения программы,
это может быть связанно с той же проблемой - размер данных слишком маленький. 

